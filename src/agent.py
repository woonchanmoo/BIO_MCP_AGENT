from langgraph.graph import StateGraph, START, END
from langchain.chat_models import init_chat_model
from langgraph.prebuilt import tools_condition
from typing import Annotated, TypedDict, Any, Sequence
from langchain_core.messages import BaseMessage, AIMessage, ToolMessage, HumanMessage, SystemMessage
from langgraph.graph.message import add_messages
from dotenv import load_dotenv

load_dotenv()

# 1. ì‹¤ì œ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•  í•¨ìˆ˜ ì •ì˜ (ì´ë¦„ì€ ìžìœ )
def handle_tool_error(error: Exception) -> str:
    print(f"--- [ðŸ”´ Tool Error Log ðŸ”´] ---\n{repr(error)}\n------------------------")
    return f"Error: {repr(error)}."

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    error_count: int


FILESYSTEM_TOOL_NAMES = {
    "list_directory",
    "read_file",
    "write_file",
    "create_directory",
    "move_file",
    "search_files",
    "get_file_info",
    "list_allowed_directories",
    "read_multiple_files",
}


def normalize_filesystem_args(tool_name: str, tool_args: Any) -> Any:
    if tool_name not in FILESYSTEM_TOOL_NAMES or not isinstance(tool_args, dict):
        return tool_args

    normalized = dict(tool_args)

    if "path" not in normalized:
        for alias in ("directory_path", "dir_path", "file_path", "folder_path"):
            if isinstance(normalized.get(alias), str):
                normalized["path"] = normalized[alias]
                break

    if tool_name == "list_directory" and not isinstance(normalized.get("path"), str):
        normalized["path"] = "."

    if tool_name == "list_directory" and normalized.get("path", "") == "":
        normalized["path"] = "."

    return normalized

def build_simple_agent(model: str, system_prompt: str, tools: Sequence[Any], checkpointer = None):
    llm = init_chat_model(model=model)
    llm_with_tools = llm.bind_tools(tools)
    tool_by_name = {tool.name: tool for tool in tools}

    async def agent_node(state: AgentState) -> AgentState:
        messages = state["messages"]
        current_errors = state.get("error_count", 0)

        # ðŸŒŸ [í•µì‹¬ ì¶”ê°€] ì‚¬ìš©ìžê°€ ìƒˆë¡œìš´ ìž…ë ¥ì„ í–ˆë‹¤ë©´ ì—ëŸ¬ ì¹´ìš´íŠ¸ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ HumanMessageë¼ë©´ ì‚¬ìš©ìžê°€ ìƒˆë¡œìš´ ì‹œë„ë¥¼ í•˜ë ¤ëŠ” ê²ƒì´ë¯€ë¡œ ì¹´ìš´íŠ¸ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤.
        # 1. ìƒˆë¡œìš´ ì§ˆë¬¸ ì‹œ ì™„ì „ ì´ˆê¸°í™” í›„ ì¦‰ì‹œ ëª¨ë¸ í˜¸ì¶œë¡œ ì í”„
        if messages and isinstance(messages[-1], HumanMessage):
            current_errors = 0
            # ê³¼ê±° ì—ëŸ¬ ê³„ì‚° ë£¨í”„ë¥¼ íƒ€ì§€ ì•Šê³  ë°”ë¡œ ëª¨ë¸ í˜¸ì¶œë¡œ ë„˜ê¹ë‹ˆë‹¤.
            llm_input = [SystemMessage(content=system_prompt), *messages]
            response = await llm_with_tools.ainvoke(llm_input)
            # (ë¡œê·¸ ì¶œë ¥ ë¡œì§ ìƒëžµ)
            return {"messages": [response], "error_count": 0}

        # 2. íˆ´ ê²°ê³¼ì— ëŒ€í•œ ì—ëŸ¬ ê³„ì‚° (ì‚¬ìš©ìž ì§ˆë¬¸ì´ ì•„ë‹ ë•Œë§Œ ì´ ì•„ëž˜ê°€ ì‹¤í–‰ë¨)
        new_errors = 0
        for msg in reversed(messages):
            if isinstance(msg, ToolMessage):
                if "Error:" in msg.content:
                    new_errors += 1
            elif isinstance(msg, AIMessage) and msg.tool_calls:
                break

        if new_errors > 0:
            current_errors += new_errors
        else:
            # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì„±ê³µí•œ íˆ´ ê²°ê³¼ë¼ë©´ ì´ˆê¸°í™”
            if messages and isinstance(messages[-1], ToolMessage):
                current_errors = 0

        # 3. ìž„ê³„ì¹˜ ì²´í¬
        if current_errors >= 5:
            return {
                "messages": [AIMessage(content="ðŸ”´ ë‹¤ìˆ˜ì˜ ë„êµ¬ í˜¸ì¶œì—ì„œ ì—°ì†ì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")],
                "error_count": current_errors
            }
        
        # 4. ëª¨ë¸ í˜¸ì¶œ (íˆ´ ê²°ê³¼ë¥¼ ë³´ê³  ë‹¤ì‹œ íŒë‹¨í•´ì•¼ í•  ë•Œ)
        llm_input = [SystemMessage(content=system_prompt), *messages]
        response = await llm_with_tools.ainvoke(llm_input)

        # # 4. ðŸ”¥ [ìµœì¢… ë¡œê·¸ í™•ì¸ ì˜ì—­] ðŸ”¥
        # print("\n\n" + "ðŸ“œ" + "="*30 + " FULL CONVERSATION LOG " + "="*30)
        # for i, msg in enumerate(messages + [response]):
        #     role = f"[{msg.type.upper()}]"
            
        #     # ë©”ì‹œì§€ ìœ í˜•ë³„ ìƒ‰ìƒ/ì´ë¦„ ì •ì˜ (í„°ë¯¸ë„ ê°€ë…ì„±)
        #     if isinstance(msg, HumanMessage):
        #         header = f"\033[92m{role} User:\033[0m" # ì´ˆë¡
        #     elif isinstance(msg, AIMessage):
        #         header = f"\033[94m{role} AI (Scout):\033[0m" # íŒŒëž‘
        #     elif isinstance(msg, ToolMessage):
        #         header = f"\033[93m{role} Tool Result:\033[0m" # ë…¸ëž‘
        #     else:
        #         header = role

        #     content = msg.content if msg.content else "(No text content)"
            
        #     # ë„êµ¬ í˜¸ì¶œ ì •ë³´ê°€ ìžˆìœ¼ë©´ ì¶”ê°€ ì¶œë ¥
        #     tool_info = ""
        #     if isinstance(msg, AIMessage) and msg.tool_calls:
        #         tool_info = f" ðŸ› ï¸ Calls: {[tc['name'] for tc in msg.tool_calls]}"

        #     print(f"{i:02d} {header}{tool_info}")
        #     # ë„ˆë¬´ ê¸¸ë©´ 150ìžë§Œ ì¶œë ¥
        #     print(f"   Content: {str(content)[:150]}..." if len(str(content)) > 150 else f"   Content: {content}")
        # print(f"\nðŸ“Š Current Status - Error Count: {current_errors}")
        # print("="*85 + "\n")

        # ì—¬ê¸°ì„œ ì§ì ‘ printí•˜ì§€ ì•Šê³  responseë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
        return {
            "messages": [response],
            "error_count": current_errors}
    
    workflow = StateGraph(AgentState)

    async def tools_node(state: AgentState) -> AgentState:
        messages = state["messages"]
        if not messages:
            return {"messages": [], "error_count": state.get("error_count", 0)}

        last_message = messages[-1]
        if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
            return {"messages": [], "error_count": state.get("error_count", 0)}

        tool_results: list[ToolMessage] = []

        for tool_call in last_message.tool_calls:
            tool_name = tool_call.get("name", "")
            tool_call_id = tool_call.get("id", "")
            raw_args = tool_call.get("args", {})
            tool_args = normalize_filesystem_args(tool_name, raw_args)

            tool = tool_by_name.get(tool_name)
            if tool is None:
                error_text = handle_tool_error(Exception(f"Tool not found: {tool_name}"))
                tool_results.append(ToolMessage(content=error_text, tool_call_id=tool_call_id, name=tool_name))
                continue

            try:
                result = await tool.ainvoke(tool_args)
                if isinstance(result, ToolMessage):
                    content = result.content
                elif isinstance(result, str):
                    content = result
                else:
                    content = str(result)
            except Exception as error:
                content = handle_tool_error(error)

            tool_results.append(ToolMessage(content=content, tool_call_id=tool_call_id, name=tool_name))

        return {"messages": tool_results, "error_count": state.get("error_count", 0)}

    workflow.add_node("Agent", agent_node)
    workflow.add_node("tools", tools_node)
    workflow.add_edge(START, "Agent")
    workflow.add_conditional_edges(
        "Agent",
        tools_condition,
        {
            "tools": "tools",
            "__end__": END
        }
    )
    workflow.add_edge("tools", "Agent")

    return workflow.compile(checkpointer=checkpointer)
